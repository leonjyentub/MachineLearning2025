{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from : https://github.com/christianversloot/machine-learning-articles/blob/main/building-a-simple-vanilla-gan-with-pytorch.md\n",
    "\n",
    "#### others: \n",
    "https://github.com/rehanfazalkhan/GAN-implementation-from-scratch-using-PyTorch/blob/main/GAN_implementation_from_scratch_using_PyTorch.ipynb\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable variables\n",
    "NUM_EPOCHS = 50\n",
    "NOISE_DIMENSION = 50\n",
    "BATCH_SIZE = 1024 #試試看調超大會怎樣\n",
    "TRAIN_ON_GPU = True\n",
    "UNIQUE_RUN_ID = str(uuid.uuid4())\n",
    "PRINT_STATS_AFTER_BATCH = 30\n",
    "OPTIMIZER_LR = 0.0002\n",
    "OPTIMIZER_BETAS = (0.5, 0.999)\n",
    "GENERATOR_OUTPUT_IMAGE_SHAPE = 28 * 28 * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed ups\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and TRAIN_ON_GPU else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  \"\"\"\n",
    "    Vanilla GAN Generator\n",
    "  \"\"\"\n",
    "  def __init__(self,):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      # First upsampling\n",
    "      nn.Linear(NOISE_DIMENSION, 128, bias=False),\n",
    "      nn.BatchNorm1d(128, 0.8),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      # Second upsampling\n",
    "      nn.Linear(128, 256, bias=False),\n",
    "      nn.BatchNorm1d(256, 0.8),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      # Third upsampling\n",
    "      nn.Linear(256, 512, bias=False),\n",
    "      nn.BatchNorm1d(512, 0.8),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      # Final upsampling\n",
    "      nn.Linear(512, GENERATOR_OUTPUT_IMAGE_SHAPE, bias=False),\n",
    "      nn.Tanh()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"Forward pass\"\"\"\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  \"\"\"\n",
    "    Vanilla GAN Discriminator\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(GENERATOR_OUTPUT_IMAGE_SHAPE, 1024),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(1024, 512),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(512, 256),\n",
    "      nn.LeakyReLU(0.25),\n",
    "      nn.Linear(256, 1),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"Forward pass\"\"\"\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directory_for_run():\n",
    "  \"\"\" Make a directory for this training run. \"\"\"\n",
    "  print(f'Preparing training run {UNIQUE_RUN_ID}')\n",
    "  if not os.path.exists('./runs'):\n",
    "    os.mkdir('./runs')\n",
    "  os.mkdir(f'./runs/{UNIQUE_RUN_ID}')\n",
    "\n",
    "def generate_image(generator, epoch = 0, batch = 0, device=device):\n",
    "  \"\"\" Generate subplots with generated examples. \"\"\"\n",
    "  images = []\n",
    "  noise = generate_noise(BATCH_SIZE, device=device)\n",
    "  generator.eval()\n",
    "  images = generator(noise)\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for i in range(16):\n",
    "    # Get image\n",
    "    image = images[i]\n",
    "    # Convert image back onto CPU and reshape\n",
    "    image = image.cpu().detach().numpy()\n",
    "    image = np.reshape(image, (28, 28))\n",
    "    # Plot\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "  if not os.path.exists(f'./runs/{UNIQUE_RUN_ID}/images'):\n",
    "    os.mkdir(f'./runs/{UNIQUE_RUN_ID}/images')\n",
    "  plt.savefig(f'./runs/{UNIQUE_RUN_ID}/images/epoch{epoch}_batch{batch}.jpg')\n",
    "\n",
    "\n",
    "def save_models(generator, discriminator, epoch):\n",
    "  \"\"\" Save models at specific point in time. \"\"\"\n",
    "  torch.save(generator.state_dict(), f'./runs/{UNIQUE_RUN_ID}/generator_{epoch}.pth')\n",
    "  torch.save(discriminator.state_dict(), f'./runs/{UNIQUE_RUN_ID}/discriminator_{epoch}.pth')\n",
    "\n",
    "\n",
    "def print_training_progress(batch, generator_loss, discriminator_loss):\n",
    "  \"\"\" Print training progress. \"\"\"\n",
    "  print('Losses after mini-batch %5d: generator %e, discriminator %e' %\n",
    "        (batch, generator_loss, discriminator_loss))\n",
    "\n",
    "def initialize_models(device = device):\n",
    "  \"\"\" Initialize Generator and Discriminator models \"\"\"\n",
    "  generator = Generator()\n",
    "  discriminator = Discriminator()\n",
    "  # Move models to specific device\n",
    "  generator.to(device)\n",
    "  discriminator.to(device)\n",
    "  # Return models\n",
    "  return generator, discriminator\n",
    "\n",
    "def initialize_optimizers(generator, discriminator):\n",
    "  \"\"\" Initialize optimizers for Generator and Discriminator. \"\"\"\n",
    "  generator_optimizer = torch.optim.AdamW(generator.parameters(), lr=OPTIMIZER_LR,betas=OPTIMIZER_BETAS)\n",
    "  discriminator_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=OPTIMIZER_LR,betas=OPTIMIZER_BETAS)\n",
    "  return generator_optimizer, discriminator_optimizer\n",
    "\n",
    "\n",
    "def generate_noise(number_of_images = 1, noise_dimension = NOISE_DIMENSION, device=None):\n",
    "  \"\"\" Generate noise for number_of_images images, with a specific noise_dimension \"\"\"\n",
    "  return torch.randn(number_of_images, noise_dimension, device=device)\n",
    "\n",
    "\n",
    "def efficient_zero_grad(model):\n",
    "  \"\"\"\n",
    "    Apply zero_grad more efficiently\n",
    "    Source: https://betterprogramming.pub/how-to-make-your-pytorch-code-run-faster-93079f3c1f7b\n",
    "  \"\"\"\n",
    "  for param in model.parameters():\n",
    "    param.grad = None\n",
    "\n",
    "\n",
    "def forward_and_backward(model, data, loss_function, targets):\n",
    "  \"\"\"\n",
    "    Perform forward and backward pass in a generic way. Returns loss value.\n",
    "  \"\"\"\n",
    "  outputs = model(data)\n",
    "  error = loss_function(outputs, targets)\n",
    "  error.backward()\n",
    "  return error.item()\n",
    "\n",
    "\n",
    "def perform_train_step(generator, discriminator, real_data, \\\n",
    "  loss_function, generator_optimizer, discriminator_optimizer, device = device):\n",
    "  \"\"\" Perform a single training step. \"\"\"\n",
    "\n",
    "  # 1. PREPARATION\n",
    "  # Set real and fake labels.\n",
    "  real_label, fake_label = 1.0, 0.0\n",
    "  # Get images on CPU or GPU as configured and available\n",
    "  # Also set 'actual batch size', whih can be smaller than BATCH_SIZE\n",
    "  # in some cases.\n",
    "  real_images = real_data[0].to(device)\n",
    "  actual_batch_size = real_images.size(0)\n",
    "  label = torch.full((actual_batch_size,1), real_label, device=device)\n",
    "\n",
    "  # 2. TRAINING THE DISCRIMINATOR\n",
    "  # Zero the gradients for discriminator\n",
    "  efficient_zero_grad(discriminator)\n",
    "  # Forward + backward on real images, reshaped\n",
    "  real_images = real_images.view(real_images.size(0), -1)\n",
    "  error_real_images = forward_and_backward(discriminator, real_images, \\\n",
    "    loss_function, label)\n",
    "  # Forward + backward on generated images\n",
    "  noise = generate_noise(actual_batch_size, device=device)\n",
    "  generated_images = generator(noise)\n",
    "  label.fill_(fake_label)\n",
    "  error_generated_images =forward_and_backward(discriminator, \\\n",
    "    generated_images.detach(), loss_function, label)\n",
    "  # Optim for discriminator\n",
    "  discriminator_optimizer.step()\n",
    "\n",
    "  # 3. TRAINING THE GENERATOR\n",
    "  # Forward + backward + optim for generator, including zero grad\n",
    "  efficient_zero_grad(generator)\n",
    "  label.fill_(real_label)\n",
    "  error_generator = forward_and_backward(discriminator, generated_images, loss_function, label)\n",
    "  generator_optimizer.step()\n",
    "\n",
    "  # 4. COMPUTING RESULTS\n",
    "  # Compute loss values in floats for discriminator, which is joint loss.\n",
    "  error_discriminator = error_real_images + error_generated_images\n",
    "  # Return generator and discriminator loss so that it can be printed.\n",
    "  return error_generator, error_discriminator\n",
    "\n",
    "\n",
    "def perform_epoch(dataloader, generator, discriminator, loss_function, \\\n",
    "    generator_optimizer, discriminator_optimizer, epoch):\n",
    "  \"\"\" Perform a single epoch. \"\"\"\n",
    "  for batch_no, real_data in enumerate(dataloader, 0):\n",
    "    # Perform training step\n",
    "    generator_loss_val, discriminator_loss_val = perform_train_step(generator, \\\n",
    "      discriminator, real_data, loss_function, \\\n",
    "      generator_optimizer, discriminator_optimizer)\n",
    "    # Print statistics and generate image after every n-th batch\n",
    "    if batch_no % PRINT_STATS_AFTER_BATCH == 0:\n",
    "      print_training_progress(batch_no, generator_loss_val, discriminator_loss_val)\n",
    "      generate_image(generator, epoch, batch_no)\n",
    "  # Save models on epoch completion.\n",
    "  save_models(generator, discriminator, epoch)\n",
    "  # Clear memory after every epoch\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Prepare dataset through DataLoader \"\"\"\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
    "\n",
    "# Download and load the training data\n",
    "dataset = datasets.MNIST('drive/My Drive/mnist/MNIST_data/', download=True, train=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training run 5a0d13e0-9833-4898-8153-ee9e5fe5c7d6\n",
      "Starting epoch 0...\n",
      "Losses after mini-batch     0: generator 6.745315e-01, discriminator 1.373417e+00\n",
      "Losses after mini-batch    50: generator 6.212007e-01, discriminator 1.078287e+00\n",
      "Losses after mini-batch   100: generator 1.404483e+00, discriminator 6.247198e-01\n",
      "Starting epoch 1...\n",
      "Losses after mini-batch     0: generator 3.689985e-01, discriminator 1.072383e+00\n",
      "Losses after mini-batch    50: generator 1.983692e+00, discriminator 2.722976e-01\n",
      "Losses after mini-batch   100: generator 2.755710e+00, discriminator 1.169302e-01\n",
      "Starting epoch 2...\n",
      "Losses after mini-batch     0: generator 3.789200e+00, discriminator 6.646004e-02\n",
      "Losses after mini-batch    50: generator 5.704900e+00, discriminator 3.682873e-02\n",
      "Losses after mini-batch   100: generator 2.393565e+00, discriminator 3.421822e-01\n",
      "Starting epoch 3...\n",
      "Losses after mini-batch     0: generator 3.211159e+00, discriminator 2.829945e-01\n",
      "Losses after mini-batch    50: generator 3.986300e+00, discriminator 1.401419e-01\n",
      "Losses after mini-batch   100: generator 7.119811e+00, discriminator 7.236647e-01\n",
      "Starting epoch 4...\n",
      "Losses after mini-batch     0: generator 5.398438e+00, discriminator 2.612873e-02\n",
      "Losses after mini-batch    50: generator 6.936637e+00, discriminator 8.176342e-02\n",
      "Losses after mini-batch   100: generator 3.408717e+00, discriminator 2.071364e-01\n",
      "Starting epoch 5...\n",
      "Losses after mini-batch     0: generator 3.551575e+00, discriminator 1.517979e-01\n",
      "Losses after mini-batch    50: generator 5.293450e+00, discriminator 9.638878e-02\n",
      "Losses after mini-batch   100: generator 1.860093e+00, discriminator 4.163845e-01\n",
      "Starting epoch 6...\n",
      "Losses after mini-batch     0: generator 3.152491e+00, discriminator 2.939717e-01\n",
      "Losses after mini-batch    50: generator 1.069174e+01, discriminator 7.050658e-01\n",
      "Losses after mini-batch   100: generator 5.250837e+00, discriminator 9.010801e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonjye\\AppData\\Local\\Temp\\ipykernel_22804\\330356377.py:14: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(10, 10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 7...\n",
      "Losses after mini-batch     0: generator 1.761207e+00, discriminator 2.146645e-01\n",
      "Losses after mini-batch    50: generator 3.871464e+00, discriminator 2.433934e-01\n",
      "Losses after mini-batch   100: generator 4.226848e+00, discriminator 1.261269e-01\n",
      "Starting epoch 8...\n",
      "Losses after mini-batch     0: generator 1.587094e+01, discriminator 7.263729e-01\n",
      "Losses after mini-batch    50: generator 3.606222e+00, discriminator 1.879246e-01\n",
      "Losses after mini-batch   100: generator 3.954991e+00, discriminator 2.142357e-01\n",
      "Starting epoch 9...\n",
      "Losses after mini-batch     0: generator 8.610691e+00, discriminator 2.461880e-01\n",
      "Losses after mini-batch    50: generator 3.521803e+00, discriminator 1.987744e-01\n",
      "Losses after mini-batch   100: generator 3.819155e+00, discriminator 1.817217e-01\n",
      "Starting epoch 10...\n",
      "Losses after mini-batch     0: generator 3.675934e+00, discriminator 1.677747e-01\n",
      "Losses after mini-batch    50: generator 4.876209e+00, discriminator 2.391697e-01\n",
      "Losses after mini-batch   100: generator 2.911419e+00, discriminator 2.022815e-01\n",
      "Starting epoch 11...\n",
      "Losses after mini-batch     0: generator 2.695614e+00, discriminator 2.978132e-01\n",
      "Losses after mini-batch    50: generator 5.509200e+00, discriminator 1.835061e-01\n",
      "Losses after mini-batch   100: generator 4.144499e+00, discriminator 1.901802e-01\n",
      "Starting epoch 12...\n",
      "Losses after mini-batch     0: generator 3.261916e+00, discriminator 2.006750e-01\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Train the DCGAN. \"\"\"\n",
    "# Make directory for unique run\n",
    "make_directory_for_run()\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "# Initialize models\n",
    "generator, discriminator = initialize_models()\n",
    "# Initialize loss and optimizers\n",
    "loss_function = nn.BCELoss()\n",
    "generator_optimizer, discriminator_optimizer = initialize_optimizers(generator, discriminator)\n",
    "# Train the model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'Starting epoch {epoch}...')\n",
    "    perform_epoch(dataloader, generator, discriminator, loss_function, \\\n",
    "    generator_optimizer, discriminator_optimizer, epoch)\n",
    "    # Finished :-)\n",
    "print(f'Finished unique run {UNIQUE_RUN_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchMLBase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
